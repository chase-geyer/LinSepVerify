{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathOptInterface.LessThan{Float64}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import MathOptInterface\n",
    "using Profile, ProfileView, Dates\n",
    "using LinearAlgebra\n",
    "using JuMP, Gurobi, Test, Ipopt, Juniper, Suppressor, Pandas\n",
    "const GT = MOI.GreaterThan{Float64}\n",
    "const LT = MOI.LessThan{Float64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-01-15\n",
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (mac64[arm] - Darwin 23.0.0 23A344)\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 1 rows, 2 columns and 2 nonzeros\n",
      "Model fingerprint: 0xc5bc6d97\n",
      "Variable types: 0 continuous, 2 integer (2 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 2e+00]\n",
      "Found heuristic solution: objective 1.0000000\n",
      "Presolve removed 1 rows and 2 columns\n",
      "Presolve time: 0.00s\n",
      "Presolve: All rows and columns removed\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 1 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.000000000000e+00, best bound 1.000000000000e+00, gap 0.0000%\n",
      "\n",
      "User-callback calls 183, time in user-callback 0.00 sec\n",
      "  0.666068 seconds (1.90 M allocations: 125.878 MiB, 5.50% gc time, 98.24% compilation time: 14% of which was recompilation)\n"
     ]
    }
   ],
   "source": [
    "model = Model(Gurobi.Optimizer)\n",
    "\n",
    "@variable(model, x, Bin)\n",
    "@variable(model, y, Bin)\n",
    "@constraint(model, x + y <= 1.5)\n",
    "@objective(model, Max, x + y)\n",
    "\n",
    "@time optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-01-15\n",
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (mac64[arm] - Darwin 23.0.0 23A344)\n",
      "\n",
      "CPU model: Apple M1\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 0 rows, 2 columns and 0 nonzeros\n",
      "Model fingerprint: 0x12a95a66\n",
      "Variable types: 0 continuous, 2 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [0e+00, 0e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [0e+00, 0e+00]\n",
      "Found heuristic solution: objective 2.0000000\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.00 seconds (0.00 work units)\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: 2 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.000000000000e+00, best bound 2.000000000000e+00, gap 0.0000%\n",
      "\n",
      "User-callback calls 24, time in user-callback 0.04 sec\n",
      "  0.043502 seconds (264.36 k allocations: 17.748 MiB, 99.65% compilation time)\n"
     ]
    }
   ],
   "source": [
    "model = direct_model(Gurobi.Optimizer())\n",
    "@variable(model, 0 <= x <= 1.0, Int)\n",
    "@variable(model, 0 <= y <= 1.0, Int)\n",
    "@objective(model, Max, x + y)\n",
    "function my_callback_function(cb_data, cb_where::Cint)\n",
    "    # You can query a callback attribute using GRBcbget\n",
    "    if cb_where == GRB_CB_MIPNODE\n",
    "        Gurobi.load_callback_variable_primal(cb_data, cb_where)\n",
    "        x_val = callback_value(cb_data, x)\n",
    "        y_val = callback_value(cb_data, y)\n",
    "        con = @build_constraint(x + y <= 1)\n",
    "        MOI.submit(model, MOI.UserCut(cb_data), con)\n",
    "    end\n",
    "    # Before querying `callback_value`, you must call:\n",
    "    #\n",
    "\n",
    "    return\n",
    "end\n",
    "\n",
    "MOI.set(model, Gurobi.CallbackFunction(), my_callback_function)\n",
    "@time optimize!(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"../CayleyVerify.jl\")\n",
    "include(\"../DeepPoly.jl\")\n",
    "import Pickle\n",
    "\n",
    "# utility functions\n",
    "function dorefa_to_staircase(k::Int)\n",
    "    n = 2^k - 1\n",
    "    slopes = zeros(n+1)\n",
    "    breakpoints = [-Inf]\n",
    "    for i in 1:n\n",
    "        push!(breakpoints, (2*i-1)/n - 1)\n",
    "    end\n",
    "    push!(breakpoints, Inf)\n",
    "    \n",
    "    constant_terms = [-1.0]\n",
    "    for i in 1:n\n",
    "        push!(constant_terms, -1.0 + 2*i/n)\n",
    "    end\n",
    "    return StaircaseFunction(breakpoints, slopes, constant_terms)\n",
    "end\n",
    "\n",
    "function predict(neural_net, img)\n",
    "    num_layers = length(neural_net.weights)\n",
    "    a = img'\n",
    "    for i in 1:num_layers\n",
    "        a = a * neural_net.weights[i] + neural_net.biases[i]'\n",
    "        if i <= num_layers -1\n",
    "            a = [eval(neural_net.activation[i], a[j]) for j in 1:length(a)]'\n",
    "        end\n",
    "    end\n",
    "    output = a'\n",
    "    return findmax(output)[2]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net loaded"
     ]
    }
   ],
   "source": [
    "net_from_pickle = Pickle.load(open(\"../models/MNIST-DoReFa3_Dense256-Dense256.pkl\"))\n",
    "f = dorefa_to_staircase(3)\n",
    "activation = [f, f]\n",
    "neural_net = NeuralNetwork(net_from_pickle, activation)\n",
    "print(\"net loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images loaded"
     ]
    }
   ],
   "source": [
    "raw_imgs = Pickle.load(open(\"../imgs/MNIST_images-for-verification\"))\n",
    "imgs = []\n",
    "for img in raw_imgs\n",
    "    img = vcat([w' for w in img] ...)\n",
    "    img = vcat(img'...)\n",
    "    push!(imgs, img)\n",
    "end\n",
    "labels = Pickle.load(open(\"../imgs/MNIST_labels-for-verification\"))\n",
    "labels = [l+1 for l in labels]\n",
    "print(\"images loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-01-15\n",
      "Set parameter OutputFlag to value 1\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$ -0.0022692241764161736 x_{3,1} - 0.0003622803487814963 x_{3,2} + 0.0013901707425247878 x_{3,3} - 0.3418678643065505 x_{3,4} + 0.0005246367290965281 x_{3,5} - 0.0010369061201345176 x_{3,6} + 0.000713563155841257 x_{3,7} - 0.0024401845294050872 x_{3,8} + 0.0010575342166703194 x_{3,9} + 0.0007439423789037392 x_{3,10} - 0.0023106156731955707 x_{3,11} + 0.001303841738263145 x_{3,12} - 0.000828511469080695 x_{3,13} - 0.0013108639395795763 x_{3,14} - 0.0011618216813076288 x_{3,15} + 0.0007242877181852236 x_{3,16} + 0.001301012996918871 x_{3,17} - 0.000801704591140151 x_{3,18} - 0.0017929214518517256 x_{3,19} + 0.001864776451839134 x_{3,20} - 0.6483434443362057 x_{3,21} + 0.0012033609491481911 x_{3,22} + 0.0011818046041298658 x_{3,23} - 0.001873847737442702 x_{3,24} + 0.0004001157485618023 x_{3,25} + 0.0005756226310040802 x_{3,26} + 0.0014854815799481003 x_{3,27} - 0.0012031871592625976 x_{3,28} - 0.0026092840016644914 x_{3,29} + 0.0009927909450198058 x_{3,30} - [[\\ldots\\text{196 terms omitted}\\ldots]] - 0.0007154121485655196 x_{3,227} - 0.001640224116272293 x_{3,228} + 0.2563808629747655 x_{3,229} + 0.3571828368876595 x_{3,230} + 0.002356326178414747 x_{3,231} - 0.002574990736320615 x_{3,232} - 0.2325345518765971 x_{3,233} + 0.0026566144661046565 x_{3,234} + 0.08063544593096594 x_{3,235} + 4.0512706618756056e-5 x_{3,236} - 1.9269507902208716e-5 x_{3,237} + 0.00216125714359805 x_{3,238} + 0.002651712915394455 x_{3,239} - 0.5615964578755666 x_{3,240} + 0.0007501267973566428 x_{3,241} - 0.0023283023037947714 x_{3,242} + 0.0007644270881428383 x_{3,243} - 0.0014578361879102886 x_{3,244} - 0.0017146319441962987 x_{3,245} + 0.23561768210493028 x_{3,246} + 0.0008534826338291168 x_{3,247} - 0.0013769206598226447 x_{3,248} + 3.507905057631433e-5 x_{3,249} - 0.0017307312227785587 x_{3,250} + 0.0023827805125620216 x_{3,251} + 0.002005490881856531 x_{3,252} + 0.0005059804825577885 x_{3,253} + 0.001029493403621018 x_{3,254} - 0.0009306890278821811 x_{3,255} + 0.0022845478379167616 x_{3,256} $"
      ],
      "text/plain": [
       "-0.0022692241764161736 x[3,1] - 0.0003622803487814963 x[3,2] + 0.0013901707425247878 x[3,3] - 0.3418678643065505 x[3,4] + 0.0005246367290965281 x[3,5] - 0.0010369061201345176 x[3,6] + 0.000713563155841257 x[3,7] - 0.0024401845294050872 x[3,8] + 0.0010575342166703194 x[3,9] + 0.0007439423789037392 x[3,10] - 0.0023106156731955707 x[3,11] + 0.001303841738263145 x[3,12] - 0.000828511469080695 x[3,13] - 0.0013108639395795763 x[3,14] - 0.0011618216813076288 x[3,15] + 0.0007242877181852236 x[3,16] + 0.001301012996918871 x[3,17] - 0.000801704591140151 x[3,18] - 0.0017929214518517256 x[3,19] + 0.001864776451839134 x[3,20] - 0.6483434443362057 x[3,21] + 0.0012033609491481911 x[3,22] + 0.0011818046041298658 x[3,23] - 0.001873847737442702 x[3,24] + 0.0004001157485618023 x[3,25] + 0.0005756226310040802 x[3,26] + 0.0014854815799481003 x[3,27] - 0.0012031871592625976 x[3,28] - 0.0026092840016644914 x[3,29] + 0.0009927909450198058 x[3,30] - [[...196 terms omitted...]] - 0.0007154121485655196 x[3,227] - 0.001640224116272293 x[3,228] + 0.2563808629747655 x[3,229] + 0.3571828368876595 x[3,230] + 0.002356326178414747 x[3,231] - 0.002574990736320615 x[3,232] - 0.2325345518765971 x[3,233] + 0.0026566144661046565 x[3,234] + 0.08063544593096594 x[3,235] + 4.0512706618756056e-5 x[3,236] - 1.9269507902208716e-5 x[3,237] + 0.00216125714359805 x[3,238] + 0.002651712915394455 x[3,239] - 0.5615964578755666 x[3,240] + 0.0007501267973566428 x[3,241] - 0.0023283023037947714 x[3,242] + 0.0007644270881428383 x[3,243] - 0.0014578361879102886 x[3,244] - 0.0017146319441962987 x[3,245] + 0.23561768210493028 x[3,246] + 0.0008534826338291168 x[3,247] - 0.0013769206598226447 x[3,248] + 3.507905057631433e-5 x[3,249] - 0.0017307312227785587 x[3,250] + 0.0023827805125620216 x[3,251] + 0.002005490881856531 x[3,252] + 0.0005059804825577885 x[3,253] + 0.001029493403621018 x[3,254] - 0.0009306890278821811 x[3,255] + 0.0022845478379167616 x[3,256]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# play around with smaller epsilons\n",
    "t = @elapsed mip, variable_neuron_dict, neuron_integervar_dict = init_mip_deeppoly(neural_net, imgs[1], 0.05)\n",
    "true_label = labels[1]\n",
    "target_label = 2\n",
    "set_attribute(mip, \"output_flag\", true)\n",
    "last_layer = last(neural_net.weights)\n",
    "objective = zeros(10)\n",
    "objective[target_label] = 1.0\n",
    "objective[true_label] = -1.0\n",
    "c = last_layer * objective\n",
    "\n",
    "for z in mip[:z]\n",
    "    set_binary(z)\n",
    "end\n",
    "\n",
    "num_layers = length(neural_net.weights)\n",
    "final_dim, output_dim = size(last_layer)\n",
    "@objective(mip, Max, sum(c[i]*mip[:x][num_layers, i] for i in 1:final_dim))\n",
    "#@time optimize!(mip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e306f22",
   "metadata": {},
   "source": [
    "## Big M MIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_m (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function run_m(num_of_callbacks_before_cut)\n",
    "    mip, variable_neuron_dict, neuron_integervar_dict = init_mip_deeppoly(neural_net, imgs[1], 0.04)\n",
    "    true_label = labels[1]\n",
    "    target_label = 2\n",
    "    set_attribute(mip, \"output_flag\", false)\n",
    "    set_optimizer_attribute(mip, \"TimeLimit\", 100) # Set a time limit of 300 seconds\n",
    "    last_layer = last(neural_net.weights)\n",
    "    objective = zeros(10) # always 10 classes\n",
    "    objective[target_label] = 1.0\n",
    "    objective[true_label] = -1.0\n",
    "    c = last_layer * objective\n",
    "\n",
    "    num_layers = length(neural_net.weights)\n",
    "    final_dim, output_dim = size(last_layer)\n",
    "    @objective(mip, Max, sum(c[i]*mip[:x][num_layers, i] for i in 1:final_dim))\n",
    "\n",
    "    neurons_by_layer = [length(bias) for bias in neural_net.biases] #including input & output layer\n",
    "    pushfirst!(neurons_by_layer, size(neural_net.weights[1])[1])\n",
    "    pop!(neurons_by_layer)\n",
    "\n",
    "    for z in mip[:z]\n",
    "    set_binary(z)\n",
    "    end\n",
    "\n",
    "    alphas = []\n",
    "    for n in neurons_by_layer\n",
    "    push!(alphas, zeros(n))\n",
    "    end\n",
    "    @time optimize!(mip)\n",
    "    #print(\"fractional calls: \", fractional_calls[1], \"\\n\")\n",
    "    #output = split(output,\" \")[2]\n",
    "    output = split(output,\" \")[2]\n",
    "    #open(\"log.txt\", \"a\") do file\n",
    "    #    write(file, \"$output\\t$num_of_callbacks_before_cut\\tbig-m\\n\")\n",
    "    #end\n",
    "    return output\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385cddde",
   "metadata": {},
   "source": [
    "## Cayley MIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbce462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_cayley (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function run_cayley(num_of_callbacks_before_cut)\n",
    "    mip, variable_neuron_dict, neuron_integervar_dict = init_mip_deeppoly(neural_net, imgs[1], 0.04)\n",
    "    true_label = labels[1]\n",
    "    target_label = 2\n",
    "    set_optimizer_attribute(mip, \"TimeLimit\", 100) # Set a time limit of 300 seconds\n",
    "    set_attribute(mip, \"output_flag\", false)\n",
    "    last_layer = last(neural_net.weights)\n",
    "    objective = zeros(10) # always 10 classes\n",
    "    objective[target_label] = 1.0\n",
    "    objective[true_label] = -1.0\n",
    "    # Calculate 'c' using matrix multiplication for vectorization\n",
    "    c = last_layer * objective\n",
    "\n",
    "    # Define the objective function in a more concise manner\n",
    "    num_layers = length(neural_net.weights)\n",
    "    final_dim, _ = size(last_layer) # Assuming output_dim is not used elsewhere\n",
    "    @objective(mip, Max, sum(c[i]*mip[:x][num_layers, i] for i in 1:final_dim))\n",
    "\n",
    "    # Efficiently compute neurons_by_layer without mutating the array\n",
    "    neurons_by_layer = [size(neural_net.weights[1])[1]; [length(bias) for bias in neural_net.biases][1:end-1]]\n",
    "\n",
    "    # Set integer constraint on z variables in a single loop\n",
    "    foreach(set_integer, mip[:z])\n",
    "\n",
    "    # Preallocate alphas with the correct dimensions and fill with zeros\n",
    "    alphas = [zeros(n) for n in neurons_by_layer]\n",
    "\n",
    "    #allocation1 = []\n",
    "    #allocation2 = []\n",
    "\n",
    "    count = [0]\n",
    "    time = []\n",
    "    function callback_cut(cb_data)\n",
    "        count[1] += 1\n",
    "        if count[1]%num_of_callbacks_before_cut == 0\n",
    "            x_val = callback_value.(Ref(cb_data), mip[:x])\n",
    "            z_val = callback_value.(Ref(cb_data), mip[:z])\n",
    "            for i in 1:num_layers-1\n",
    "                bias = neural_net.biases[i]\n",
    "                weight = neural_net.weights[i]\n",
    "                n, m = size(weight)\n",
    "                for j in 1:m\n",
    "                    num_pieces = neuron_integervar_dict[(i+1,j)]\n",
    "                    z = [z_val[i+1,j,k] for k in 1:num_pieces]\n",
    "                    fractional = any(1e-6 < val < 1-1e-6 for val in z)\n",
    "                    if !fractional\n",
    "                        continue\n",
    "                    end\n",
    "                    y = x_val[i+1, j]\n",
    "                    x = [x_val[i, k] for k in 1:n]\n",
    "                    neuron = variable_neuron_dict[mip[:x][i+1, j]]\n",
    "                    update = update_alpha!(neuron, x, y, z, alphas[i])\n",
    "                    if update\n",
    "                        upper_z = generate_zcoef_from_alpha(neuron, alphas[i], GT(y))\n",
    "                        lower_z = generate_zcoef_from_alpha(neuron, alphas[i], LT(y))\n",
    "                        upper_con = @build_constraint(mip[:x][i+1, j] <= sum(mip[:x][i, k]*alphas[i][k] for \n",
    "                                    k in 1:n) + sum(mip[:z][i+1, j, p]*upper_z[p] for p in 1:num_pieces))\n",
    "                        lower_con = @build_constraint(mip[:x][i+1, j] >= sum(mip[:x][i, k]*alphas[i][k] for \n",
    "                                    k in 1:n) + sum(mip[:z][i+1, j, p]*lower_z[p] for p in 1:num_pieces))\n",
    "                        MOI.submit(mip, MOI.UserCut(cb_data), upper_con)\n",
    "                        MOI.submit(mip, MOI.UserCut(cb_data), lower_con)\n",
    "                        #push!(allocation2, t2+t3)\n",
    "                    end\n",
    "                    #push!(time, [time_update, time_uzcoef, time_lzcoef])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    #record opt gap and nodes using verbose model output\n",
    "    MOI.set(mip, MOI.UserCutCallback(), callback_cut)\n",
    "    @time optimize!(mip)\n",
    "    #print(\"fractional calls: \", fractional_calls[1], \"\\n\")\n",
    "    output = split(output,\" \")[2]\n",
    "    #open(\"log.txt\", \"a\") do f\n",
    "    #    write(f, \"$output\\t$num_of_callbacks_before_cut\\tcayley\\n\")\n",
    "    #end\n",
    "    return output\n",
    "    #return time\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c83ed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-01-15\n"
     ]
    }
   ],
   "source": [
    "profile_time = 0\n",
    "run_cayley(150)\n",
    "run_m(150)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26647e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(profile_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720db99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_arrs = [[],[]]\n",
    "@suppress begin \n",
    "    idx = 0\n",
    "    while idx < 5\n",
    "        push!(val_arrs[1], parse(Float64, run_cayley(150)))\n",
    "        push!(val_arrs[2],  parse(Float64,run_m(150)))\n",
    "        idx += 1\n",
    "    end\n",
    "end\n",
    "cayley_avg = mean(val_arrs[1])\n",
    "m_avg = mean(val_arrs[2])\n",
    "print(\"$cayley_avg\\t$m_avg\\n\")\n",
    "#running tally:\n",
    "# cayley: III\n",
    "# m: \n",
    "# cayley: 14.891829570000004\tm: 14.952998299999997 (averaged over 100 runs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0b97e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cayley(150)\n",
    "run_m(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be26fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B\n",
    "write(\"log.txt\", \"time\\tcut_freq\\tmethod\\n\")\n",
    "cayley_results = Dict{Int, Array{Any,1}}()\n",
    "m_results = Dict{Int, Array{Any,1}}()\n",
    "\n",
    "for num in range(25, 500, step=25)\n",
    "    cayley_results[num] = []\n",
    "    m_results[num] = []\n",
    "    for _ in range(1,5)\n",
    "        push!(cayley_results[num], run_cayley(num))\n",
    "    end\n",
    "    for _ in range(1,5)\n",
    "        push!(m_results[num], run_m(num))\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results = []\n",
    "#print(\"cayley_results: $cayley_results\\n\")\n",
    "for (key, value) in cayley_results\n",
    "    print(\"key: $key, value: $value\\n\")\n",
    "    final_val = [parse(Float64, val) for val in value]\n",
    "    push!(avg_results, (key, mean(final_val), \"cayley\"))\n",
    "end\n",
    "\n",
    "for (key, value) in m_results\n",
    "    print(\"key: $key, value: $value\\n\")\n",
    "    final_val = [parse(Float64, val) for val in value]\n",
    "    push!(avg_results, (key, mean(final_val), \"big-m\"))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cayley_callback_debugging(150)\n",
    "avg_results = sort!(avg_results, by=x->x[2])\n",
    "\n",
    "print(avg_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
