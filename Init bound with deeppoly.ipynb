{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using TimerOutputs\n",
    "\n",
    "include(\"CayleyVerify.jl\")\n",
    "include(\"DeepPoly.jl\")\n",
    "\n",
    "function dorefa_to_staircase(k::Int)\n",
    "    n = 2^k - 1\n",
    "    slopes = zeros(n+1)\n",
    "    breakpoints = [-Inf]\n",
    "    for i in 1:n\n",
    "        push!(breakpoints, (2*i-1)/n - 1)\n",
    "    end\n",
    "    push!(breakpoints, Inf)\n",
    "    \n",
    "    constant_terms = [-1.0]\n",
    "    for i in 1:n\n",
    "        push!(constant_terms, -1.0 + 2*i/n)\n",
    "    end\n",
    "    return StaircaseFunction(breakpoints, slopes, constant_terms)\n",
    "end\n",
    "\n",
    "function predict(neural_net, img)\n",
    "    num_layers = length(neural_net.weights)\n",
    "    a = img'\n",
    "    for i in 1:num_layers\n",
    "        a = a * neural_net.weights[i] + neural_net.biases[i]'\n",
    "        if i <= num_layers -1\n",
    "            a = [eval(neural_net.activation[i], a[j]) for j in 1:length(a)]'\n",
    "        end\n",
    "    end\n",
    "    output = a'\n",
    "    return findmax(output)[2]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: Cannot `convert` an object of type Vector{Any} to an object of type Float64\n\nClosest candidates are:\n  convert(::Type{T}, !Matched::T) where T<:Number\n   @ Base number.jl:6\n  convert(::Type{T}, !Matched::Number) where T<:Number\n   @ Base number.jl:7\n  convert(::Type{T}, !Matched::Base.TwicePrecision) where T<:Number\n   @ Base twiceprecision.jl:273\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: Cannot `convert` an object of type Vector{Any} to an object of type Float64\n",
      "\n",
      "Closest candidates are:\n",
      "  convert(::Type{T}, !Matched::T) where T<:Number\n",
      "   @ Base number.jl:6\n",
      "  convert(::Type{T}, !Matched::Number) where T<:Number\n",
      "   @ Base number.jl:7\n",
      "  convert(::Type{T}, !Matched::Base.TwicePrecision) where T<:Number\n",
      "   @ Base twiceprecision.jl:273\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      "  [1] setindex!(A::Vector{Float64}, x::Vector{Any}, i1::Int64)\n",
      "    @ Base ./array.jl:969\n",
      "  [2] _unsafe_copyto!(dest::Vector{Float64}, doffs::Int64, src::Vector{Any}, soffs::Int64, n::Int64)\n",
      "    @ Base ./array.jl:250\n",
      "  [3] unsafe_copyto!\n",
      "    @ ./array.jl:304 [inlined]\n",
      "  [4] _copyto_impl!\n",
      "    @ ./array.jl:327 [inlined]\n",
      "  [5] copyto!\n",
      "    @ ./array.jl:314 [inlined]\n",
      "  [6] copyto!\n",
      "    @ ./array.jl:339 [inlined]\n",
      "  [7] copyto_axcheck!\n",
      "    @ ./abstractarray.jl:1182 [inlined]\n",
      "  [8] Vector{Float64}(x::Vector{Any})\n",
      "    @ Base ./array.jl:621\n",
      "  [9] convert\n",
      "    @ ./array.jl:613 [inlined]\n",
      " [10] setindex!(A::Vector{Vector{Float64}}, x::Vector{Any}, i1::Int64)\n",
      "    @ Base ./array.jl:969\n",
      " [11] _unsafe_copyto!(dest::Vector{Vector{Float64}}, doffs::Int64, src::Vector{Any}, soffs::Int64, n::Int64)\n",
      "    @ Base ./array.jl:250\n",
      " [12] unsafe_copyto!\n",
      "    @ ./array.jl:304 [inlined]\n",
      " [13] _copyto_impl!\n",
      "    @ ./array.jl:327 [inlined]\n",
      " [14] copyto!\n",
      "    @ ./array.jl:314 [inlined]\n",
      " [15] copyto!\n",
      "    @ ./array.jl:339 [inlined]\n",
      " [16] copyto_axcheck!\n",
      "    @ ./abstractarray.jl:1182 [inlined]\n",
      " [17] Vector{Vector{Float64}}(x::Vector{Any})\n",
      "    @ Base ./array.jl:621\n",
      " [18] convert\n",
      "    @ ./array.jl:613 [inlined]\n",
      " [19] NeuralNetwork\n",
      "    @ ~/OR-Research/LinSepVerify/CayleyVerify.jl:101 [inlined]\n",
      " [20] NeuralNetwork(net_from_pickle::Vector{Any}, activation::Vector{StaircaseFunction})\n",
      "    @ Main ~/OR-Research/LinSepVerify/CayleyVerify.jl:119\n",
      " [21] top-level scope\n",
      "    @ ~/OR-Research/LinSepVerify/Init bound with deeppoly.ipynb:8"
     ]
    }
   ],
   "source": [
    "using Pickle\n",
    "using Suppressor\n",
    "using Printf\n",
    "\n",
    "net_from_pickle = Pickle.load(open(\"./models/MNIST-DoReFa3_Dense256-Dense256.pkl\"))\n",
    "f = dorefa_to_staircase(3)\n",
    "activation = [f, f]\n",
    "neural_net = NeuralNetwork(net_from_pickle, activation)\n",
    "print(\"net loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_imgs = Pickle.load(open(\"./imgs/MNIST_images-for-verification\"))\n",
    "imgs = []\n",
    "for img in raw_imgs\n",
    "    img = vcat([w' for w in img] ...)\n",
    "    img = vcat(img'...)\n",
    "    push!(imgs, img)\n",
    "end\n",
    "labels = Pickle.load(open(\"./imgs/MNIST_labels-for-verification\", \"r+\"))\n",
    "labels = Array{Int64}(labels.args[2][5])\n",
    "labels = [l+1 for l in labels]\n",
    "print(\"images loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cayley Embedding Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `neural_net` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `neural_net` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] macro expansion\n",
      "   @ ~/OR-Research/LinSepVerify/Init bound with deeppoly.ipynb:10 [inlined]\n",
      " [2] macro expansion\n",
      "   @ ~/.julia/packages/Suppressor/2hiVi/src/Suppressor.jl:22 [inlined]\n",
      " [3] top-level scope\n",
      "   @ ~/OR-Research/LinSepVerify/Init bound with deeppoly.ipynb:9"
     ]
    }
   ],
   "source": [
    "upper_bound = 150\n",
    "lower_bound = 0\n",
    "count = 1\n",
    "for (img, label) in zip(imgs, labels)\n",
    "    @printf(\"Verify %d-th image \\n\", count)\n",
    "    vulnerable = false\n",
    "    for target_label in 1:10\n",
    "        if target_label != label\n",
    "            @suppress begin\n",
    "                opt_val, opt_sol_x, opt_sol_z = target_attack(neural_net, img, label, target_label, 0.008)\n",
    "                if opt_val > 0\n",
    "                    vulnerable = true\n",
    "                    adv_img = [opt_sol_x[1, j] for j in 1:784]\n",
    "                    pred = predict(neural_net, adv_img)\n",
    "                    if pred != label\n",
    "                        upper_bound -= 1\n",
    "                        break\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    if vulnerable == false\n",
    "        lower_bound += 1\n",
    "    end\n",
    "    count += 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching length(::Pickle.Defer)\n\nClosest candidates are:\n  length(!Matched::Union{Base.KeySet, Base.ValueIterator})\n   @ Base abstractdict.jl:58\n  length(!Matched::Union{Adjoint{T, S}, Transpose{T, S}} where {T, S})\n   @ LinearAlgebra /opt/homebrew/Cellar/julia/1.9.4/share/julia/stdlib/v1.9/LinearAlgebra/src/adjtrans.jl:295\n  length(!Matched::Union{SparseArrays.FixedSparseVector{Tv, Ti}, SparseArrays.SparseVector{Tv, Ti}} where {Tv, Ti})\n   @ SparseArrays /opt/homebrew/Cellar/julia/1.9.4/share/julia/stdlib/v1.9/SparseArrays/src/sparsevector.jl:95\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching length(::Pickle.Defer)\n",
      "\n",
      "Closest candidates are:\n",
      "  length(!Matched::Union{Base.KeySet, Base.ValueIterator})\n",
      "   @ Base abstractdict.jl:58\n",
      "  length(!Matched::Union{Adjoint{T, S}, Transpose{T, S}} where {T, S})\n",
      "   @ LinearAlgebra /opt/homebrew/Cellar/julia/1.9.4/share/julia/stdlib/v1.9/LinearAlgebra/src/adjtrans.jl:295\n",
      "  length(!Matched::Union{SparseArrays.FixedSparseVector{Tv, Ti}, SparseArrays.SparseVector{Tv, Ti}} where {Tv, Ti})\n",
      "   @ SparseArrays /opt/homebrew/Cellar/julia/1.9.4/share/julia/stdlib/v1.9/SparseArrays/src/sparsevector.jl:95\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] length(g::Base.Generator{Pickle.Defer, var\"#525#526\"})\n",
      "   @ Base ./generator.jl:50\n",
      " [2] _similar_shape(itr::Base.Generator{Pickle.Defer, var\"#525#526\"}, #unused#::Base.HasLength)\n",
      "   @ Base ./array.jl:658\n",
      " [3] collect(itr::Base.Generator{Pickle.Defer, var\"#525#526\"})\n",
      "   @ Base ./array.jl:781\n",
      " [4] NeuralNetwork(net_from_pickle::Vector{Any}, activation::Vector{StaircaseFunction})\n",
      "   @ Main ~/OR-Research/LinSepVerify/CayleyVerify.jl:114\n",
      " [5] top-level scope\n",
      "   @ ~/OR-Research/LinSepVerify/Init bound with deeppoly.ipynb:4"
     ]
    }
   ],
   "source": [
    "net_from_pickle = Pickle.load(open(\"./models/MNIST-DoReFa2_Dense256-Dense256.pkl\"))\n",
    "f = dorefa_to_staircase(2)\n",
    "activation = [f, f]\n",
    "neural_net = NeuralNetwork(net_from_pickle, activation)\n",
    "print(\"net loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big-M Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `neural_net` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `neural_net` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] macro expansion\n",
      "   @ ~/OR-Research/LinSepVerify/Init bound with deeppoly.ipynb:10 [inlined]\n",
      " [2] macro expansion\n",
      "   @ ~/.julia/packages/Suppressor/2hiVi/src/Suppressor.jl:22 [inlined]\n",
      " [3] top-level scope\n",
      "   @ ~/OR-Research/LinSepVerify/Init bound with deeppoly.ipynb:9"
     ]
    }
   ],
   "source": [
    "upper_bound = 150\n",
    "lower_bound = 0\n",
    "count = 1\n",
    "for (img, label) in zip(imgs, labels)\n",
    "    @printf(\"Verify %d-th image \\n\", count)\n",
    "    vulnerable = false\n",
    "    for target_label in 1:10\n",
    "        if target_label != label\n",
    "            @suppress begin\n",
    "                mip, _, _ = init_mip_deeppoly(neural_net, img, 0.008)\n",
    "                last_layer = last(neural_net.weights)\n",
    "                objective = zeros(10) # always 10 classes\n",
    "                objective[target_label] = 1.0\n",
    "                objective[label] = -1.0\n",
    "                c = last_layer * objective\n",
    "\n",
    "                num_layers = length(neural_net.weights)\n",
    "                final_dim, output_dim = size(last_layer)\n",
    "                @objective(mip, Max, sum(c[i]*mip[:x][num_layers, i] for i in 1:final_dim))\n",
    "                optimize!(mip)\n",
    "                opt_val = objective_value(mip)\n",
    "                if opt_val > 0\n",
    "                    vulnerable = true\n",
    "                    break\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    if vulnerable == false\n",
    "        lower_bound += 1\n",
    "    end\n",
    "    count += 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
